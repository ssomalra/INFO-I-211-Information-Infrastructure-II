{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329286a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f075af6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spam_mails = pd.read_csv('/Users/sahitisomalraju/Downloads/spam_ham_dataset 2.csv')\n",
    "spam_mails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160b331",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87bb6d7",
   "metadata": {},
   "source": [
    "### Get the shape of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2ec858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_mails.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6e40f",
   "metadata": {},
   "source": [
    "### Using one of the built-in functions for one of the libraries that you have learned during this course, define how many emails are spam (label_num=1) and how many emails are not spam (label_num=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1435ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n",
      "3672\n"
     ]
    }
   ],
   "source": [
    "spam = (spam_mails['label_num']==1)\n",
    "spam_sum = spam.sum()\n",
    "print(spam_sum)\n",
    "\n",
    "non_spam = (spam_mails['label_num']==0)\n",
    "non_spam_sum = non_spam.sum()\n",
    "print(non_spam_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07014d5",
   "metadata": {},
   "source": [
    "### Plot a bar graph that shows the counts of spam and non-spam emails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef5df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = ['Spam', 'Non-spam']\n",
    "y = [spam_sum, non_spam_sum]\n",
    "plt.bar(x, y)\n",
    "\n",
    "plt.title('Counts of Spam and Non-spam Emails')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed91f72",
   "metadata": {},
   "source": [
    "### Tokenize the email subject text of the 140th sample of the dataset once into words. How many words have you got after tokenization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a169d8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: fw : fw : equistar 1373 for march\\r\\ndaren - i won ' t be here on friday but tom acton will back me up .\\r\\nmegan parker keeps asking me for an answer - have you had a chance to decide what to do ?\\r\\nthanks - julie\\r\\n- - - - - original message - - - - -\\r\\nfrom : parker , megan\\r\\nsent : thursday , april 26 , 2001 8 : 34 am\\r\\nto : kemp , juliann\\r\\nsubject : re : fw : equistar 1373 for march\\r\\nhave you heard from daren yet ? equistar won ' t pay the invoice until we bill it correctly . thanks for you help . i know it ' s bid week .\\r\\nmegan\\r\\nfrom : juliann kemp / enron @ enronxgate on 04 / 25 / 2001 10 : 22 am\\r\\nto : megan parker / corp / enron @ enron\\r\\ncc :\\r\\nsubject : fw : equistar 1373 for march\\r\\ni sent this to daren farmer - to give me direction for the missing gas volumes .\\r\\nthe deals went to ' 0 ' in sitara by the trader and amiee confirmed it for the following days . thanks - julie\\r\\n- - - - - original message - - - - -\\r\\nfrom : kemp , juliann\\r\\nsent : wednesday , april 25 , 2001 10 : 18 am\\r\\nto : farmer , daren j .\\r\\nsubject : equistar for march\\r\\nmarch -\\r\\nmeter 1373\\r\\ndeal 165373 for 10 , 000 ( 3 rd , 4 th , 5 th ) total 310 , 000\\r\\ndeal 157572 for 5 , 000 ( 3 rd ) total 155 , 000\\r\\ndeal was taken to zero in sitara - equistar said it should of been kept whole for the whole month .\\r\\nwhat do you want me to do so equistar can pay their invoice . thanks - julie\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_subject_text1 = spam_mails.loc[140, 'text']\n",
    "email_subject_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62acf16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text_tokenized = word_tokenize(email_subject_text1)\n",
    "len(text_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f2b1b",
   "metadata": {},
   "source": [
    "### Clean the email subject text of the 1265th sample of the dataset by removing stopwords. How many stopwords are in that text? Also, how many words are in the filtered/clean text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7aff90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: re : shell meters for october\\r\\nshell has made the following adjustment : 1581 = 10 m ; 1095 = 45 . net volume\\r\\nis still 90 m'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_subject_text2 = spam_mails.loc[1265, 'text']\n",
    "email_subject_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52becd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = word_tokenize(email_subject_text2)\n",
    "len(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31113e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords in text: 7\n",
      "Number of words in filtered text: 23\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "filtered_words2=[]\n",
    "for word in words2:\n",
    "    if word.casefold() not in stop_words:\n",
    "        filtered_words2.append(word)\n",
    "\n",
    "print('Number of stopwords in text:', len(words2)-len(filtered_words2))\n",
    "print('Number of words in filtered text:', len(filtered_words2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc0627",
   "metadata": {},
   "source": [
    "### Reduce the words of the email subject text of the 1835th sample of the dataset to its word root by performing stemming and to its meaningful base by performing lemmatization. Next check if stemming and lemmatization outputs are equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a07ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: cp & l\\r\\nthanks for your help .\\r\\nrebecca\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by rebecca griffin / na / enron on 03 / 30 / 2001 04 : 11 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\njanet h wallis @ ect\\r\\n03 / 29 / 2001 08 : 49 am\\r\\nto : rebecca griffin / na / enron @ enron\\r\\ncc :\\r\\nsubject : cp & l\\r\\nplease add a spot sale for feb 21 at $ 5 . 16 for 5 k .\\r\\nthanks janet'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_subject_text3 = spam_mails.loc[1835, 'text']\n",
    "email_subject_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9c8d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words3 = word_tokenize(email_subject_text3)\n",
    "len(words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f249cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "filtered_words3=[]\n",
    "for word in words3:\n",
    "    if word.casefold() not in stop_words:\n",
    "        filtered_words3.append(word)\n",
    "\n",
    "print(len(filtered_words3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ab5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject', ':', 'cp', '&', 'l', 'thank', 'help', '.', 'rebecca', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forward', 'rebecca', 'griffin', '/', 'na', '/', 'enron', '03', '/', '30', '/', '2001', '04', ':', '11', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'janet', 'h', 'walli', '@', 'ect', '03', '/', '29', '/', '2001', '08', ':', '49', ':', 'rebecca', 'griffin', '/', 'na', '/', 'enron', '@', 'enron', 'cc', ':', 'subject', ':', 'cp', '&', 'l', 'pleas', 'add', 'spot', 'sale', 'feb', '21', '$', '5', '.', '16', '5', 'k', '.', 'thank', 'janet']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words3]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efc3a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject', ':', 'cp', '&', 'l', 'thanks', 'help', '.', 'rebecca', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forwarded', 'rebecca', 'griffin', '/', 'na', '/', 'enron', '03', '/', '30', '/', '2001', '04', ':', '11', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'janet', 'h', 'wallis', '@', 'ect', '03', '/', '29', '/', '2001', '08', ':', '49', ':', 'rebecca', 'griffin', '/', 'na', '/', 'enron', '@', 'enron', 'cc', ':', 'subject', ':', 'cp', '&', 'l', 'please', 'add', 'spot', 'sale', 'feb', '21', '$', '5', '.', '16', '5', 'k', '.', 'thanks', 'janet']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatize_words = [lemmatizer.lemmatize(word) for word in filtered_words3]\n",
    "print(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62830ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs are not equal\n",
      "Words that are different: ['pleas', 'walli', 'thank', 'forward']\n"
     ]
    }
   ],
   "source": [
    "# Check if stemming and lemmatization outputs are equal.\n",
    "if stemmed_words == lemmatize_words:\n",
    "    print('Outputs are equal')\n",
    "else:\n",
    "    print('Outputs are not equal')\n",
    "    difference = list(set(stemmed_words) - set(lemmatize_words))\n",
    "    print('Words that are different:', difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc7f27",
   "metadata": {},
   "source": [
    "### Make a part of speech (POS) tagging to words of the email subject text of the 5011th sample of the dataset and print the POS tag of each word and its description by querying about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3474c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: copanos changes\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 06 / 06 / 2000\\r\\n02 : 06 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\ntroy _ a _ benoit @ reliantenergy . com on 06 / 06 / 2000 10 : 35 : 09 am\\r\\nto : \" ami chokshi \"\\r\\ncc :\\r\\nsubject : copanos changes\\r\\n( see attached file : hpl - june . xls )\\r\\n- hpl - june . xls'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_subject_text4 = spam_mails.loc[5011, 'text']\n",
    "email_subject_text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff8d0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words4 = word_tokenize(email_subject_text4)\n",
    "len(words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee1ae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "filtered_words4=[]\n",
    "for word in words4:\n",
    "    if word.casefold() not in stop_words:\n",
    "        filtered_words4.append(word)\n",
    "\n",
    "print(len(filtered_words4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fd487df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_words = [lemmatizer.lemmatize(word) for word in filtered_words4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7e49f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Subject', 'JJ'),\n",
       " (':', ':'),\n",
       " ('copanos', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('forwarded', 'VBD'),\n",
       " ('ami', 'JJ'),\n",
       " ('chokshi', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('corp', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('enron', 'VBZ'),\n",
       " ('06', 'CD'),\n",
       " ('/', 'NN'),\n",
       " ('06', 'CD'),\n",
       " ('/', 'NN'),\n",
       " ('2000', 'CD'),\n",
       " ('02', 'CD'),\n",
       " (':', ':'),\n",
       " ('06', 'CD'),\n",
       " ('pm', 'NN'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('-', ':'),\n",
       " ('troy', 'NN'),\n",
       " ('_', 'JJ'),\n",
       " ('_', 'NNP'),\n",
       " ('benoit', 'NN'),\n",
       " ('@', 'NNP'),\n",
       " ('reliantenergy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('com', 'VB'),\n",
       " ('06', 'CD'),\n",
       " ('/', 'JJ'),\n",
       " ('06', 'CD'),\n",
       " ('/', 'JJ'),\n",
       " ('2000', 'CD'),\n",
       " ('10', 'CD'),\n",
       " (':', ':'),\n",
       " ('35', 'CD'),\n",
       " (':', ':'),\n",
       " ('09', 'CD'),\n",
       " (':', ':'),\n",
       " ('``', '``'),\n",
       " ('ami', 'VB'),\n",
       " ('chokshi', 'NN'),\n",
       " ('``', '``'),\n",
       " ('cc', 'NN'),\n",
       " (':', ':'),\n",
       " ('subject', 'NN'),\n",
       " (':', ':'),\n",
       " ('copanos', 'NN'),\n",
       " ('change', 'NN'),\n",
       " ('(', '('),\n",
       " ('see', 'VB'),\n",
       " ('attached', 'VBN'),\n",
       " ('file', 'NN'),\n",
       " (':', ':'),\n",
       " ('hpl', 'NN'),\n",
       " ('-', ':'),\n",
       " ('june', 'NN'),\n",
       " ('.', '.'),\n",
       " ('xl', 'NN'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('hpl', 'NN'),\n",
       " ('-', ':'),\n",
       " ('june', 'NN'),\n",
       " ('.', '.'),\n",
       " ('xl', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(lemmatize_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde6d83",
   "metadata": {},
   "source": [
    "# 2. Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf232115",
   "metadata": {},
   "source": [
    "### Generate features from email subject texts in your dataset once using the bag of words approach and another time using the TF-IDF approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc7c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = spam_mails['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1735b4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 50447)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def feature_bow(text):\n",
    "    # converts a collection of text documents to a matrix of token counts\n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    # transforms text to numbers to count how many times each word existed in given dataset\n",
    "    features = cv.fit_transform(text)\n",
    "    return features\n",
    "features_bag_words = feature_bow(text)\n",
    "features_bag_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e5603ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 50447)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def feature_tfidf(text):\n",
    "    tf = TfidfVectorizer()\n",
    "    features = tf.fit_transform(text)\n",
    "    return features\n",
    "features_tfidf = feature_tfidf(text)\n",
    "features_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b31ab",
   "metadata": {},
   "source": [
    "# 3. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c568dc6",
   "metadata": {},
   "source": [
    "### Develop a random forest classifier / SVM classifier that can be trained using the features that you have generated using the bag of words approach and fit on 80 % of this dataset for training and predict the class of email either spam or not on the remaining 20 % of this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b9abaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = spam_mails['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627ce6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4136, 50447)\n",
      "(4136,)\n",
      "(1035, 50447)\n",
      "(1035,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features_bag_words, target, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21987052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "model = clf.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6954543",
   "metadata": {},
   "source": [
    "### Test your classifier's performance by reporting its accuracy, precision, recall, and F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf6ae794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9671497584541063\n",
      "Precision Score: 0.9308176100628931\n",
      "Recall Score: 0.961038961038961\n",
      "F1 Score: 0.9456869009584665\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "acc = metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('Accuracy Score:', acc)\n",
    "\n",
    "prec = metrics.precision_score(Y_test, Y_pred)\n",
    "print('Precision Score:', prec)\n",
    "\n",
    "recall = metrics.recall_score(Y_test, Y_pred)\n",
    "print('Recall Score:', recall)\n",
    "\n",
    "f1 = metrics.f1_score(Y_test, Y_pred)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af50a7f",
   "metadata": {},
   "source": [
    "### Again, develop a random forest classifier that can be trained using the features that you have generated using the TF-IDF approach and fit on 80 % of this dataset for training and predict the class of email either spam or not on the remaining 20 % of this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a08ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "clf = rf()\n",
    "model = clf.fit(X_train, Y_train)\n",
    "Y_pred2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557fafc8",
   "metadata": {},
   "source": [
    "### Test your classifier's performance by reporting its accuracy/ precision/ recall/ F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a36a666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9758454106280193\n",
      "Precision Score: 0.9796610169491525\n",
      "Recall Score: 0.9383116883116883\n",
      "F1 Score: 0.9585406301824212\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(Y_test, Y_pred2)\n",
    "print('Accuracy Score:', acc)\n",
    "\n",
    "prec = metrics.precision_score(Y_test, Y_pred2)\n",
    "print('Precision Score:', prec)\n",
    "\n",
    "recall = metrics.recall_score(Y_test, Y_pred2)\n",
    "print('Recall Score:', recall)\n",
    "\n",
    "f1 = metrics.f1_score(Y_test, Y_pred2)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65f425",
   "metadata": {},
   "source": [
    "### Compare the performance results of your classifier when trained with the features generated by the bag of words approach and when trained with the features generated by the TF-IDF approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bbcb9",
   "metadata": {},
   "source": [
    "It looks like the Support Vector Machine trained with features generated by the bag of words approach is comparable to the random forest classifier trained with features generated by the TF-IDF approach.\n",
    "\n",
    "The accuracy and f1 scores are almost the same between the two models with the random forest classifier being slightly higher. For the precision score, the random forest classifier had a much higher result (almost 5% higher). For the recall score, on the other hand, the support vector machine had a better result (about 3% higher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e32f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
